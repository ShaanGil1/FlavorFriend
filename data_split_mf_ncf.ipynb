{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_csv('yelp_dataset/business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b['id'] = df_b.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df_b.drop(['address','city','state','postal_code','latitude','longitude','is_open','hours'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_to_id = {}\n",
    "for i,r in df_b.iterrows():\n",
    "    bid_to_id[r['business_id']] = r['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('yelp_dataset/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users['id'] = df_users.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_id = {}\n",
    "for i,r in df_users.iterrows():\n",
    "    uid_to_id[r['user_id']] = r['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = df_users.drop(['yelping_since','elite','friends'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(idx, length):\n",
    "   a = torch.zeros(length)\n",
    "   a[idx] = 1\n",
    "   return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('yelp_dataset/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.893, 'pos': 0.107, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.66, 'pos': 0.34, 'compou...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xs8Z8lmKkosqW5mw_sVAoA</td>\n",
       "      <td>IQsF3Rc6IgCzjVV9DE8KXg</td>\n",
       "      <td>eFvzHawVJofxSnD7TgbZtg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My absolute favorite cafe in the city. Their b...</td>\n",
       "      <td>2014-11-12 15:30:27</td>\n",
       "      <td>{'neg': 0.025, 'neu': 0.738, 'pos': 0.237, 'co...</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G_5UczbCBJriUAbxz3J7Tw</td>\n",
       "      <td>clWLI5OZP2ad25ugMVI8gg</td>\n",
       "      <td>x4XdNhp0Xn8lOivzc77J-g</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Best thai food in the area.  Everything was au...</td>\n",
       "      <td>2013-08-15 15:27:51</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.586, 'pos': 0.414, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DyrAIuKl60j_X8Yrrv-kpg</td>\n",
       "      <td>mNsVyC9tQVYtzLOCbh2Piw</td>\n",
       "      <td>MWmXGQ98KbRo3vsS5nZhMA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I recently had dinner here with my wife over t...</td>\n",
       "      <td>2014-10-27 02:47:28</td>\n",
       "      <td>{'neg': 0.026, 'neu': 0.753, 'pos': 0.221, 'co...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "2  Xs8Z8lmKkosqW5mw_sVAoA  IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg   \n",
       "3  G_5UczbCBJriUAbxz3J7Tw  clWLI5OZP2ad25ugMVI8gg  x4XdNhp0Xn8lOivzc77J-g   \n",
       "4  DyrAIuKl60j_X8Yrrv-kpg  mNsVyC9tQVYtzLOCbh2Piw  MWmXGQ98KbRo3vsS5nZhMA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    3.0       0      0     0   \n",
       "1    5.0       1      0     1   \n",
       "2    5.0       0      0     0   \n",
       "3    5.0       0      0     0   \n",
       "4    5.0       1      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "2  My absolute favorite cafe in the city. Their b...  2014-11-12 15:30:27   \n",
       "3  Best thai food in the area.  Everything was au...  2013-08-15 15:27:51   \n",
       "4  I recently had dinner here with my wife over t...  2014-10-27 02:47:28   \n",
       "\n",
       "                                               score  negative  neutral  \\\n",
       "0  {'neg': 0.0, 'neu': 0.893, 'pos': 0.107, 'comp...     0.000    0.893   \n",
       "1  {'neg': 0.0, 'neu': 0.66, 'pos': 0.34, 'compou...     0.000    0.660   \n",
       "2  {'neg': 0.025, 'neu': 0.738, 'pos': 0.237, 'co...     0.025    0.738   \n",
       "3  {'neg': 0.0, 'neu': 0.586, 'pos': 0.414, 'comp...     0.000    0.586   \n",
       "4  {'neg': 0.026, 'neu': 0.753, 'pos': 0.221, 'co...     0.026    0.753   \n",
       "\n",
       "   positive  compound  \n",
       "0     0.107    0.8597  \n",
       "1     0.340    0.9588  \n",
       "2     0.237    0.9679  \n",
       "3     0.414    0.8910  \n",
       "4     0.221    0.9646  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['user_id'] = df_reviews['user_id'].map(uid_to_id)\n",
    "df_reviews['business_id'] = df_reviews['business_id'].map(bid_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncf = df_reviews.drop(['review_id','useful','funny','cool','text','date','score','negative','neutral','positive'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19125</td>\n",
       "      <td>98</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23563</td>\n",
       "      <td>334</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5260</td>\n",
       "      <td>259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3177</td>\n",
       "      <td>332</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20118</td>\n",
       "      <td>458</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  business_id  stars  compound\n",
       "0    19125           98    3.0    0.8597\n",
       "1    23563          334    5.0    0.9588\n",
       "2     5260          259    5.0    0.9679\n",
       "3     3177          332    5.0    0.8910\n",
       "4    20118          458    5.0    0.9646"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ncf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_businesses = len(df_users), len(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncf2 = df_ncf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncf2['score'] = df_ncf2['stars'] + df_ncf2['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncf2 = df_ncf2.drop(['stars','compound'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncf2 = df_ncf2.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embed = nn.Embedding(self.input_size, self.embed_size)\n",
    "        self.fc1 = nn.Linear(2 * self.embed_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = nn.Linear(self.hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        user_embed = self.embed(x[0])\n",
    "        item_embed = self.embed(x[1])\n",
    "        out = self.fc1(torch.concat((user_embed,item_embed)))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = num_users + num_businesses\n",
    "embed_size = 32\n",
    "hidden_size = 128\n",
    "model = NCF(input_size=input_size, embed_size=embed_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (embed): Embedding(75901, 32)\n",
      "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = torch.tensor(df_ncf2.iloc[:,:-1].values), torch.tensor(df_ncf2.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "split_idx = int(len(x) * split)\n",
    "train_x, test_x, train_y, test_y = x[:split_idx], x[split_idx:], y[:split_idx], y[split_idx:]\n",
    "data = (train_x, test_x, train_y, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs, optimizer, criterion):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        for i in range(len(train_x)):\n",
    "            x,y = train_x[i], train_y[i].to(torch.float32)\n",
    "            model.zero_grad()\n",
    "            pred_y = model(x)\n",
    "            loss = criterion(y, pred_y)\n",
    "            train_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100000 == 0 and i != 0:\n",
    "                b = train_loss / i\n",
    "                print(f'train_loss ({i}/{len(train_x)}): {b}')\n",
    "            \n",
    "\n",
    "        for i in range(len(test_x)):\n",
    "            x,y = test_x[i], test_y[i]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_y = model(x)\n",
    "                loss = criterion(y, pred_y)\n",
    "                test_loss += loss\n",
    "            \n",
    "        train_loss /= len(train_x)\n",
    "        test_loss /= len(test_x)\n",
    "\n",
    "        print(f'Epoch {epoch+1}:\\t Train Loss:{train_loss}\\t Test Loss:{test_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "reg_rate = 1e-6\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=reg_rate)\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss (1000/500882): 2.543792486190796\n",
      "train_loss (2000/500882): 2.687988758087158\n",
      "train_loss (3000/500882): 2.673556327819824\n",
      "train_loss (4000/500882): 2.714850425720215\n",
      "train_loss (5000/500882): 2.7638819217681885\n",
      "train_loss (6000/500882): 2.7824065685272217\n",
      "train_loss (7000/500882): 2.7613420486450195\n",
      "train_loss (8000/500882): 2.760427236557007\n",
      "train_loss (9000/500882): 2.780895948410034\n",
      "train_loss (10000/500882): 2.7654783725738525\n",
      "train_loss (11000/500882): 2.7550716400146484\n",
      "train_loss (12000/500882): 2.7615208625793457\n",
      "train_loss (13000/500882): 2.7493019104003906\n",
      "train_loss (14000/500882): 2.7289795875549316\n",
      "train_loss (15000/500882): 2.718489170074463\n",
      "train_loss (16000/500882): 2.718994140625\n",
      "train_loss (17000/500882): 2.710357189178467\n",
      "train_loss (18000/500882): 2.6980860233306885\n",
      "train_loss (19000/500882): 2.686115026473999\n",
      "train_loss (20000/500882): 2.674257755279541\n",
      "train_loss (21000/500882): 2.6662936210632324\n",
      "train_loss (22000/500882): 2.6636886596679688\n",
      "train_loss (23000/500882): 2.671922445297241\n",
      "train_loss (24000/500882): 2.6639211177825928\n",
      "train_loss (25000/500882): 2.6602048873901367\n",
      "train_loss (26000/500882): 2.6543972492218018\n",
      "train_loss (27000/500882): 2.6466305255889893\n",
      "train_loss (28000/500882): 2.64278244972229\n",
      "train_loss (29000/500882): 2.6396915912628174\n",
      "train_loss (30000/500882): 2.643079996109009\n",
      "train_loss (31000/500882): 2.635873794555664\n",
      "train_loss (32000/500882): 2.6277916431427\n",
      "train_loss (33000/500882): 2.624781370162964\n",
      "train_loss (34000/500882): 2.625916004180908\n",
      "train_loss (35000/500882): 2.623774528503418\n",
      "train_loss (36000/500882): 2.619044780731201\n",
      "train_loss (37000/500882): 2.616276502609253\n",
      "train_loss (38000/500882): 2.6110284328460693\n",
      "train_loss (39000/500882): 2.6032791137695312\n",
      "train_loss (40000/500882): 2.6012728214263916\n",
      "train_loss (41000/500882): 2.5957717895507812\n",
      "train_loss (42000/500882): 2.5931856632232666\n",
      "train_loss (43000/500882): 2.589482545852661\n",
      "train_loss (44000/500882): 2.5827715396881104\n",
      "train_loss (45000/500882): 2.5819242000579834\n",
      "train_loss (46000/500882): 2.574294090270996\n",
      "train_loss (47000/500882): 2.5743210315704346\n",
      "train_loss (48000/500882): 2.5702474117279053\n",
      "train_loss (49000/500882): 2.569721221923828\n",
      "train_loss (50000/500882): 2.5676300525665283\n",
      "train_loss (51000/500882): 2.5650267601013184\n",
      "train_loss (52000/500882): 2.5633890628814697\n",
      "train_loss (53000/500882): 2.5666160583496094\n",
      "train_loss (54000/500882): 2.5599288940429688\n",
      "train_loss (55000/500882): 2.5573394298553467\n",
      "train_loss (56000/500882): 2.5522661209106445\n",
      "train_loss (57000/500882): 2.5513389110565186\n",
      "train_loss (58000/500882): 2.5478549003601074\n",
      "train_loss (59000/500882): 2.550678014755249\n",
      "train_loss (60000/500882): 2.5474066734313965\n",
      "train_loss (61000/500882): 2.5472235679626465\n",
      "train_loss (62000/500882): 2.542393922805786\n",
      "train_loss (63000/500882): 2.538184881210327\n",
      "train_loss (64000/500882): 2.533700942993164\n",
      "train_loss (65000/500882): 2.5301425457000732\n",
      "train_loss (66000/500882): 2.5307493209838867\n",
      "train_loss (67000/500882): 2.528897762298584\n",
      "train_loss (68000/500882): 2.5314645767211914\n",
      "train_loss (69000/500882): 2.531759023666382\n",
      "train_loss (70000/500882): 2.5296597480773926\n",
      "train_loss (71000/500882): 2.524674892425537\n",
      "train_loss (72000/500882): 2.5250730514526367\n",
      "train_loss (73000/500882): 2.521101236343384\n",
      "train_loss (74000/500882): 2.516786575317383\n",
      "train_loss (75000/500882): 2.5120432376861572\n",
      "train_loss (76000/500882): 2.5096216201782227\n",
      "train_loss (77000/500882): 2.5074164867401123\n",
      "train_loss (78000/500882): 2.5065255165100098\n",
      "train_loss (79000/500882): 2.504962921142578\n",
      "train_loss (80000/500882): 2.5037407875061035\n",
      "train_loss (81000/500882): 2.502105236053467\n",
      "train_loss (82000/500882): 2.5007150173187256\n",
      "train_loss (83000/500882): 2.5004677772521973\n",
      "train_loss (84000/500882): 2.4986939430236816\n",
      "train_loss (85000/500882): 2.495441198348999\n",
      "train_loss (86000/500882): 2.4955101013183594\n",
      "train_loss (87000/500882): 2.4921576976776123\n",
      "train_loss (88000/500882): 2.494004011154175\n",
      "train_loss (89000/500882): 2.4955780506134033\n",
      "train_loss (90000/500882): 2.4932477474212646\n",
      "train_loss (91000/500882): 2.491036891937256\n",
      "train_loss (92000/500882): 2.489652633666992\n",
      "train_loss (93000/500882): 2.4884033203125\n",
      "train_loss (94000/500882): 2.4852333068847656\n",
      "train_loss (95000/500882): 2.4836716651916504\n",
      "train_loss (96000/500882): 2.482959032058716\n",
      "train_loss (97000/500882): 2.4817285537719727\n",
      "train_loss (98000/500882): 2.4795525074005127\n",
      "train_loss (99000/500882): 2.479491949081421\n",
      "train_loss (100000/500882): 2.4795031547546387\n",
      "train_loss (101000/500882): 2.476325273513794\n",
      "train_loss (102000/500882): 2.474285125732422\n",
      "train_loss (103000/500882): 2.474112033843994\n",
      "train_loss (104000/500882): 2.473477363586426\n",
      "train_loss (105000/500882): 2.472933053970337\n",
      "train_loss (106000/500882): 2.4712393283843994\n",
      "train_loss (107000/500882): 2.4705822467803955\n",
      "train_loss (108000/500882): 2.4697792530059814\n",
      "train_loss (109000/500882): 2.469120979309082\n",
      "train_loss (110000/500882): 2.4683172702789307\n",
      "train_loss (111000/500882): 2.4677071571350098\n",
      "train_loss (112000/500882): 2.467085838317871\n",
      "train_loss (113000/500882): 2.465665817260742\n",
      "train_loss (114000/500882): 2.4639222621917725\n",
      "train_loss (115000/500882): 2.4626882076263428\n",
      "train_loss (116000/500882): 2.4610755443573\n",
      "train_loss (117000/500882): 2.458865165710449\n",
      "train_loss (118000/500882): 2.4566996097564697\n",
      "train_loss (119000/500882): 2.456923246383667\n",
      "train_loss (120000/500882): 2.456413507461548\n",
      "train_loss (121000/500882): 2.455960988998413\n",
      "train_loss (122000/500882): 2.4542059898376465\n",
      "train_loss (123000/500882): 2.452035903930664\n",
      "train_loss (124000/500882): 2.4528121948242188\n",
      "train_loss (125000/500882): 2.4523956775665283\n",
      "train_loss (126000/500882): 2.4520416259765625\n",
      "train_loss (127000/500882): 2.450960397720337\n",
      "train_loss (128000/500882): 2.449784517288208\n",
      "train_loss (129000/500882): 2.4490644931793213\n",
      "train_loss (130000/500882): 2.448996067047119\n",
      "train_loss (131000/500882): 2.4482500553131104\n",
      "train_loss (132000/500882): 2.4480929374694824\n",
      "train_loss (133000/500882): 2.4473373889923096\n",
      "train_loss (134000/500882): 2.446112871170044\n",
      "train_loss (135000/500882): 2.444432497024536\n",
      "train_loss (136000/500882): 2.4436593055725098\n",
      "train_loss (137000/500882): 2.443260431289673\n",
      "train_loss (138000/500882): 2.4407637119293213\n",
      "train_loss (139000/500882): 2.4405407905578613\n",
      "train_loss (140000/500882): 2.4404773712158203\n",
      "train_loss (141000/500882): 2.4399631023406982\n",
      "train_loss (142000/500882): 2.439544439315796\n",
      "train_loss (143000/500882): 2.440141439437866\n",
      "train_loss (144000/500882): 2.4404137134552\n",
      "train_loss (145000/500882): 2.4396674633026123\n",
      "train_loss (146000/500882): 2.438547372817993\n",
      "train_loss (147000/500882): 2.4379777908325195\n",
      "train_loss (148000/500882): 2.437940835952759\n",
      "train_loss (149000/500882): 2.4380462169647217\n",
      "train_loss (150000/500882): 2.4369943141937256\n",
      "train_loss (151000/500882): 2.4383933544158936\n",
      "train_loss (152000/500882): 2.437645435333252\n",
      "train_loss (153000/500882): 2.4362521171569824\n",
      "train_loss (154000/500882): 2.43582820892334\n",
      "train_loss (155000/500882): 2.4344639778137207\n",
      "train_loss (156000/500882): 2.433108329772949\n",
      "train_loss (157000/500882): 2.4326372146606445\n",
      "train_loss (158000/500882): 2.4314308166503906\n",
      "train_loss (159000/500882): 2.431899070739746\n",
      "train_loss (160000/500882): 2.431000232696533\n",
      "train_loss (161000/500882): 2.431142568588257\n",
      "train_loss (162000/500882): 2.429189920425415\n",
      "train_loss (163000/500882): 2.4284772872924805\n",
      "train_loss (164000/500882): 2.4272212982177734\n",
      "train_loss (165000/500882): 2.426159381866455\n",
      "train_loss (166000/500882): 2.425222635269165\n",
      "train_loss (167000/500882): 2.4253430366516113\n",
      "train_loss (168000/500882): 2.4258251190185547\n",
      "train_loss (169000/500882): 2.4248740673065186\n",
      "train_loss (170000/500882): 2.42537522315979\n",
      "train_loss (171000/500882): 2.4255053997039795\n",
      "train_loss (172000/500882): 2.4242005348205566\n",
      "train_loss (173000/500882): 2.422884464263916\n",
      "train_loss (174000/500882): 2.422459840774536\n",
      "train_loss (175000/500882): 2.421391487121582\n",
      "train_loss (176000/500882): 2.421013593673706\n",
      "train_loss (177000/500882): 2.420694351196289\n",
      "train_loss (178000/500882): 2.4202780723571777\n",
      "train_loss (179000/500882): 2.4207816123962402\n",
      "train_loss (180000/500882): 2.420884609222412\n",
      "train_loss (181000/500882): 2.419489622116089\n",
      "train_loss (182000/500882): 2.4187355041503906\n",
      "train_loss (183000/500882): 2.418893337249756\n",
      "train_loss (184000/500882): 2.4198861122131348\n",
      "train_loss (185000/500882): 2.41937255859375\n",
      "train_loss (186000/500882): 2.4188740253448486\n",
      "train_loss (187000/500882): 2.4185051918029785\n",
      "train_loss (188000/500882): 2.4172773361206055\n",
      "train_loss (189000/500882): 2.416583776473999\n",
      "train_loss (190000/500882): 2.415984630584717\n",
      "train_loss (191000/500882): 2.416044235229492\n",
      "train_loss (192000/500882): 2.415344715118408\n",
      "train_loss (193000/500882): 2.4156010150909424\n",
      "train_loss (194000/500882): 2.4161956310272217\n",
      "train_loss (195000/500882): 2.4147026538848877\n",
      "train_loss (196000/500882): 2.413033962249756\n",
      "train_loss (197000/500882): 2.412519693374634\n",
      "train_loss (198000/500882): 2.412142753601074\n",
      "train_loss (199000/500882): 2.412419080734253\n",
      "train_loss (200000/500882): 2.412227153778076\n",
      "train_loss (201000/500882): 2.4127001762390137\n",
      "train_loss (202000/500882): 2.412388801574707\n",
      "train_loss (203000/500882): 2.4124248027801514\n",
      "train_loss (204000/500882): 2.412346601486206\n",
      "train_loss (205000/500882): 2.411747455596924\n",
      "train_loss (206000/500882): 2.4115569591522217\n",
      "train_loss (207000/500882): 2.411214828491211\n",
      "train_loss (208000/500882): 2.4102530479431152\n",
      "train_loss (209000/500882): 2.4102094173431396\n",
      "train_loss (210000/500882): 2.4098408222198486\n",
      "train_loss (211000/500882): 2.410334825515747\n",
      "train_loss (212000/500882): 2.410022735595703\n",
      "train_loss (213000/500882): 2.4095308780670166\n",
      "train_loss (214000/500882): 2.40753436088562\n",
      "train_loss (215000/500882): 2.407975673675537\n",
      "train_loss (216000/500882): 2.4069480895996094\n",
      "train_loss (217000/500882): 2.406705856323242\n",
      "train_loss (218000/500882): 2.406588315963745\n",
      "train_loss (219000/500882): 2.4062998294830322\n",
      "train_loss (220000/500882): 2.405745506286621\n",
      "train_loss (221000/500882): 2.405754327774048\n",
      "train_loss (222000/500882): 2.406074285507202\n",
      "train_loss (223000/500882): 2.406376600265503\n",
      "train_loss (224000/500882): 2.405935287475586\n",
      "train_loss (225000/500882): 2.4056873321533203\n",
      "train_loss (226000/500882): 2.4056484699249268\n",
      "train_loss (227000/500882): 2.404606819152832\n",
      "train_loss (228000/500882): 2.4044430255889893\n",
      "train_loss (229000/500882): 2.404458999633789\n",
      "train_loss (230000/500882): 2.403623342514038\n",
      "train_loss (231000/500882): 2.402813673019409\n",
      "train_loss (232000/500882): 2.4020469188690186\n",
      "train_loss (233000/500882): 2.4023077487945557\n",
      "train_loss (234000/500882): 2.4017906188964844\n",
      "train_loss (235000/500882): 2.401176929473877\n",
      "train_loss (236000/500882): 2.3996260166168213\n",
      "train_loss (237000/500882): 2.3989784717559814\n",
      "train_loss (238000/500882): 2.397808790206909\n",
      "train_loss (239000/500882): 2.3978233337402344\n",
      "train_loss (240000/500882): 2.3979363441467285\n",
      "train_loss (241000/500882): 2.398085355758667\n",
      "train_loss (242000/500882): 2.3984549045562744\n",
      "train_loss (243000/500882): 2.3996970653533936\n",
      "train_loss (244000/500882): 2.39965558052063\n",
      "train_loss (245000/500882): 2.3985543251037598\n",
      "train_loss (246000/500882): 2.3978359699249268\n",
      "train_loss (247000/500882): 2.3971056938171387\n",
      "train_loss (248000/500882): 2.3961808681488037\n",
      "train_loss (249000/500882): 2.3956711292266846\n",
      "train_loss (250000/500882): 2.397120952606201\n",
      "train_loss (251000/500882): 2.3969757556915283\n",
      "train_loss (252000/500882): 2.3959081172943115\n",
      "train_loss (253000/500882): 2.3956551551818848\n",
      "train_loss (254000/500882): 2.3951785564422607\n",
      "train_loss (255000/500882): 2.394505262374878\n",
      "train_loss (256000/500882): 2.3940861225128174\n",
      "train_loss (257000/500882): 2.3930561542510986\n",
      "train_loss (258000/500882): 2.3931710720062256\n",
      "train_loss (259000/500882): 2.393014907836914\n",
      "train_loss (260000/500882): 2.392775774002075\n",
      "train_loss (261000/500882): 2.392500638961792\n",
      "train_loss (262000/500882): 2.3923752307891846\n",
      "train_loss (263000/500882): 2.392378091812134\n",
      "train_loss (264000/500882): 2.3915719985961914\n",
      "train_loss (265000/500882): 2.391244411468506\n",
      "train_loss (266000/500882): 2.3909173011779785\n",
      "train_loss (267000/500882): 2.3908047676086426\n",
      "train_loss (268000/500882): 2.3905506134033203\n",
      "train_loss (269000/500882): 2.3903346061706543\n",
      "train_loss (270000/500882): 2.39009165763855\n",
      "train_loss (271000/500882): 2.390270948410034\n",
      "train_loss (272000/500882): 2.3903603553771973\n",
      "train_loss (273000/500882): 2.389883518218994\n",
      "train_loss (274000/500882): 2.3894736766815186\n",
      "train_loss (275000/500882): 2.389819622039795\n",
      "train_loss (276000/500882): 2.3901350498199463\n",
      "train_loss (277000/500882): 2.3898632526397705\n",
      "train_loss (278000/500882): 2.3903610706329346\n",
      "train_loss (279000/500882): 2.39090633392334\n",
      "train_loss (280000/500882): 2.390439987182617\n",
      "train_loss (281000/500882): 2.38956880569458\n",
      "train_loss (282000/500882): 2.3890631198883057\n",
      "train_loss (283000/500882): 2.3890254497528076\n",
      "train_loss (284000/500882): 2.38883900642395\n",
      "train_loss (285000/500882): 2.3879427909851074\n",
      "train_loss (286000/500882): 2.387274980545044\n",
      "train_loss (287000/500882): 2.3870253562927246\n",
      "train_loss (288000/500882): 2.3867127895355225\n",
      "train_loss (289000/500882): 2.3872835636138916\n",
      "train_loss (290000/500882): 2.38687801361084\n",
      "train_loss (291000/500882): 2.3861916065216064\n",
      "train_loss (292000/500882): 2.3852450847625732\n",
      "train_loss (293000/500882): 2.3854451179504395\n",
      "train_loss (294000/500882): 2.385505199432373\n",
      "train_loss (295000/500882): 2.3851797580718994\n",
      "train_loss (296000/500882): 2.3855326175689697\n",
      "train_loss (297000/500882): 2.3857569694519043\n",
      "train_loss (298000/500882): 2.38523268699646\n",
      "train_loss (299000/500882): 2.3848257064819336\n",
      "train_loss (300000/500882): 2.3852996826171875\n",
      "train_loss (301000/500882): 2.385073184967041\n",
      "train_loss (302000/500882): 2.384528875350952\n",
      "train_loss (303000/500882): 2.3844761848449707\n",
      "train_loss (304000/500882): 2.3847413063049316\n",
      "train_loss (305000/500882): 2.38362455368042\n",
      "train_loss (306000/500882): 2.383805751800537\n",
      "train_loss (307000/500882): 2.3832433223724365\n",
      "train_loss (308000/500882): 2.3831913471221924\n",
      "train_loss (309000/500882): 2.382692813873291\n",
      "train_loss (310000/500882): 2.3824198246002197\n",
      "train_loss (311000/500882): 2.381725788116455\n",
      "train_loss (312000/500882): 2.3814351558685303\n",
      "train_loss (313000/500882): 2.3814096450805664\n",
      "train_loss (314000/500882): 2.381206512451172\n",
      "train_loss (315000/500882): 2.380920886993408\n",
      "train_loss (316000/500882): 2.3806843757629395\n",
      "train_loss (317000/500882): 2.3809189796447754\n",
      "train_loss (318000/500882): 2.380838394165039\n",
      "train_loss (319000/500882): 2.38066029548645\n",
      "train_loss (320000/500882): 2.3804104328155518\n",
      "train_loss (321000/500882): 2.380406379699707\n",
      "train_loss (322000/500882): 2.3806798458099365\n",
      "train_loss (323000/500882): 2.380728244781494\n",
      "train_loss (324000/500882): 2.3803811073303223\n",
      "train_loss (325000/500882): 2.3809430599212646\n",
      "train_loss (326000/500882): 2.3808481693267822\n",
      "train_loss (327000/500882): 2.38046932220459\n",
      "train_loss (328000/500882): 2.3800055980682373\n",
      "train_loss (329000/500882): 2.3802330493927\n",
      "train_loss (330000/500882): 2.3795974254608154\n",
      "train_loss (331000/500882): 2.3794877529144287\n",
      "train_loss (332000/500882): 2.379181146621704\n",
      "train_loss (333000/500882): 2.3794538974761963\n",
      "train_loss (334000/500882): 2.3795082569122314\n",
      "train_loss (335000/500882): 2.3789377212524414\n",
      "train_loss (336000/500882): 2.379051685333252\n",
      "train_loss (337000/500882): 2.3788394927978516\n",
      "train_loss (338000/500882): 2.378278970718384\n",
      "train_loss (339000/500882): 2.3779947757720947\n",
      "train_loss (340000/500882): 2.377495050430298\n",
      "train_loss (341000/500882): 2.377164840698242\n",
      "train_loss (342000/500882): 2.3774726390838623\n",
      "train_loss (343000/500882): 2.377152681350708\n",
      "train_loss (344000/500882): 2.3767008781433105\n",
      "train_loss (345000/500882): 2.3765223026275635\n",
      "train_loss (346000/500882): 2.3762457370758057\n",
      "train_loss (347000/500882): 2.376462459564209\n",
      "train_loss (348000/500882): 2.3762474060058594\n",
      "train_loss (349000/500882): 2.376152515411377\n",
      "train_loss (350000/500882): 2.376357078552246\n",
      "train_loss (351000/500882): 2.3758203983306885\n",
      "train_loss (352000/500882): 2.3754608631134033\n",
      "train_loss (353000/500882): 2.375802993774414\n",
      "train_loss (354000/500882): 2.3753275871276855\n",
      "train_loss (355000/500882): 2.3748481273651123\n",
      "train_loss (356000/500882): 2.374577283859253\n",
      "train_loss (357000/500882): 2.374776601791382\n",
      "train_loss (358000/500882): 2.3751001358032227\n",
      "train_loss (359000/500882): 2.3750462532043457\n",
      "train_loss (360000/500882): 2.374634265899658\n",
      "train_loss (361000/500882): 2.3747127056121826\n",
      "train_loss (362000/500882): 2.3750154972076416\n",
      "train_loss (363000/500882): 2.3752024173736572\n",
      "train_loss (364000/500882): 2.3744356632232666\n",
      "train_loss (365000/500882): 2.3736860752105713\n",
      "train_loss (366000/500882): 2.3737142086029053\n",
      "train_loss (367000/500882): 2.3734560012817383\n",
      "train_loss (368000/500882): 2.374068260192871\n",
      "train_loss (369000/500882): 2.3734848499298096\n",
      "train_loss (370000/500882): 2.372889995574951\n",
      "train_loss (371000/500882): 2.372668504714966\n",
      "train_loss (372000/500882): 2.3721811771392822\n",
      "train_loss (373000/500882): 2.3719606399536133\n",
      "train_loss (374000/500882): 2.371948719024658\n",
      "train_loss (375000/500882): 2.3716766834259033\n",
      "train_loss (376000/500882): 2.371248960494995\n",
      "train_loss (377000/500882): 2.3709499835968018\n",
      "train_loss (378000/500882): 2.3707594871520996\n",
      "train_loss (379000/500882): 2.370769739151001\n",
      "train_loss (380000/500882): 2.370762825012207\n",
      "train_loss (381000/500882): 2.37105655670166\n",
      "train_loss (382000/500882): 2.3710813522338867\n",
      "train_loss (383000/500882): 2.3715126514434814\n",
      "train_loss (384000/500882): 2.3717453479766846\n",
      "train_loss (385000/500882): 2.370950222015381\n",
      "train_loss (386000/500882): 2.370600700378418\n",
      "train_loss (387000/500882): 2.370779514312744\n",
      "train_loss (388000/500882): 2.3705809116363525\n",
      "train_loss (389000/500882): 2.3705508708953857\n",
      "train_loss (390000/500882): 2.3700528144836426\n",
      "train_loss (391000/500882): 2.3698387145996094\n",
      "train_loss (392000/500882): 2.369866371154785\n",
      "train_loss (393000/500882): 2.370267868041992\n",
      "train_loss (394000/500882): 2.3702218532562256\n",
      "train_loss (395000/500882): 2.3698153495788574\n",
      "train_loss (396000/500882): 2.369520902633667\n",
      "train_loss (397000/500882): 2.3695530891418457\n",
      "train_loss (398000/500882): 2.369374990463257\n",
      "train_loss (399000/500882): 2.3694262504577637\n",
      "train_loss (400000/500882): 2.3695547580718994\n",
      "train_loss (401000/500882): 2.369227409362793\n",
      "train_loss (402000/500882): 2.3687660694122314\n",
      "train_loss (403000/500882): 2.3686861991882324\n",
      "train_loss (404000/500882): 2.3685615062713623\n",
      "train_loss (405000/500882): 2.368772268295288\n",
      "train_loss (406000/500882): 2.368595838546753\n",
      "train_loss (407000/500882): 2.368344306945801\n",
      "train_loss (408000/500882): 2.3684027194976807\n",
      "train_loss (409000/500882): 2.3682665824890137\n",
      "train_loss (410000/500882): 2.368298292160034\n",
      "train_loss (411000/500882): 2.368489980697632\n",
      "train_loss (412000/500882): 2.368497371673584\n",
      "train_loss (413000/500882): 2.3688254356384277\n",
      "train_loss (414000/500882): 2.3684732913970947\n",
      "train_loss (415000/500882): 2.3683412075042725\n",
      "train_loss (416000/500882): 2.3684563636779785\n",
      "train_loss (417000/500882): 2.368420362472534\n",
      "train_loss (418000/500882): 2.3683793544769287\n",
      "train_loss (419000/500882): 2.368347644805908\n",
      "train_loss (420000/500882): 2.367847442626953\n",
      "train_loss (421000/500882): 2.3678109645843506\n",
      "train_loss (422000/500882): 2.3675084114074707\n",
      "train_loss (423000/500882): 2.3674769401550293\n",
      "train_loss (424000/500882): 2.3677382469177246\n",
      "train_loss (425000/500882): 2.3677165508270264\n",
      "train_loss (426000/500882): 2.3675317764282227\n",
      "train_loss (427000/500882): 2.3675131797790527\n",
      "train_loss (428000/500882): 2.3671610355377197\n",
      "train_loss (429000/500882): 2.366900682449341\n",
      "train_loss (430000/500882): 2.3665871620178223\n",
      "train_loss (431000/500882): 2.3660528659820557\n",
      "train_loss (432000/500882): 2.3667023181915283\n",
      "train_loss (433000/500882): 2.366786003112793\n",
      "train_loss (434000/500882): 2.366381883621216\n",
      "train_loss (435000/500882): 2.3656022548675537\n",
      "train_loss (436000/500882): 2.364863157272339\n",
      "train_loss (437000/500882): 2.3643486499786377\n",
      "train_loss (438000/500882): 2.364053726196289\n",
      "train_loss (439000/500882): 2.363710641860962\n",
      "train_loss (440000/500882): 2.363713502883911\n",
      "train_loss (441000/500882): 2.363271474838257\n",
      "train_loss (442000/500882): 2.3627805709838867\n",
      "train_loss (443000/500882): 2.3629720211029053\n",
      "train_loss (444000/500882): 2.362626791000366\n",
      "train_loss (445000/500882): 2.3628089427948\n",
      "train_loss (446000/500882): 2.362985610961914\n",
      "train_loss (447000/500882): 2.3630311489105225\n",
      "train_loss (448000/500882): 2.3628594875335693\n",
      "train_loss (449000/500882): 2.362647771835327\n",
      "train_loss (450000/500882): 2.3631839752197266\n",
      "train_loss (451000/500882): 2.362907648086548\n",
      "train_loss (452000/500882): 2.362130641937256\n",
      "train_loss (453000/500882): 2.3622241020202637\n",
      "train_loss (454000/500882): 2.3625741004943848\n",
      "train_loss (455000/500882): 2.3624768257141113\n",
      "train_loss (456000/500882): 2.3626174926757812\n",
      "train_loss (457000/500882): 2.362175703048706\n",
      "train_loss (458000/500882): 2.3620779514312744\n",
      "train_loss (459000/500882): 2.362313747406006\n",
      "train_loss (460000/500882): 2.3621444702148438\n",
      "train_loss (461000/500882): 2.3620152473449707\n",
      "train_loss (462000/500882): 2.3617613315582275\n",
      "train_loss (463000/500882): 2.361518144607544\n",
      "train_loss (464000/500882): 2.3616726398468018\n",
      "train_loss (465000/500882): 2.362152338027954\n",
      "train_loss (466000/500882): 2.362239360809326\n",
      "train_loss (467000/500882): 2.3622167110443115\n",
      "train_loss (468000/500882): 2.3624446392059326\n",
      "train_loss (469000/500882): 2.3629162311553955\n",
      "train_loss (470000/500882): 2.362649917602539\n",
      "train_loss (471000/500882): 2.36225962638855\n",
      "train_loss (472000/500882): 2.362189531326294\n",
      "train_loss (473000/500882): 2.3618416786193848\n",
      "train_loss (474000/500882): 2.361741065979004\n",
      "train_loss (475000/500882): 2.36163067817688\n",
      "train_loss (476000/500882): 2.360917806625366\n",
      "train_loss (477000/500882): 2.360997438430786\n",
      "train_loss (478000/500882): 2.3606350421905518\n",
      "train_loss (479000/500882): 2.3607499599456787\n",
      "train_loss (480000/500882): 2.3604257106781006\n",
      "train_loss (481000/500882): 2.3603858947753906\n",
      "train_loss (482000/500882): 2.3605966567993164\n",
      "train_loss (483000/500882): 2.360399007797241\n",
      "train_loss (484000/500882): 2.3603858947753906\n",
      "train_loss (485000/500882): 2.360152006149292\n",
      "train_loss (486000/500882): 2.360022783279419\n",
      "train_loss (487000/500882): 2.359543561935425\n",
      "train_loss (488000/500882): 2.359550714492798\n",
      "train_loss (489000/500882): 2.359213352203369\n",
      "train_loss (490000/500882): 2.359553813934326\n",
      "train_loss (491000/500882): 2.3594141006469727\n",
      "train_loss (492000/500882): 2.359360694885254\n"
     ]
    }
   ],
   "source": [
    "train(model, data, epochs, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ncf_params.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6240proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
