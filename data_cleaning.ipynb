{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "business_json_path = 'D:\\FlavorFriend\\yelp_dataset\\\\yelp_academic_dataset_business.json'\n",
    "df_b = pd.read_json(business_json_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acff641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Wheelc...</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>{'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150341</th>\n",
       "      <td>IUQopTMmYQG-qRtBk-8QnA</td>\n",
       "      <td>Binh's Nails</td>\n",
       "      <td>3388 Gateway Blvd</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>T6J 5H2</td>\n",
       "      <td>53.468419</td>\n",
       "      <td>-113.492054</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ByAppointmentOnly': 'False', 'RestaurantsPri...</td>\n",
       "      <td>Nail Salons, Beauty &amp; Spas</td>\n",
       "      <td>{'Monday': '10:0-19:30', 'Tuesday': '10:0-19:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150342</th>\n",
       "      <td>c8GjPIOTGVmIemT7j5_SyQ</td>\n",
       "      <td>Wild Birds Unlimited</td>\n",
       "      <td>2813 Bransford Ave</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37204</td>\n",
       "      <td>36.115118</td>\n",
       "      <td>-86.766925</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Restau...</td>\n",
       "      <td>Pets, Nurseries &amp; Gardening, Pet Stores, Hobby...</td>\n",
       "      <td>{'Monday': '9:30-17:30', 'Tuesday': '9:30-17:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150343</th>\n",
       "      <td>_QAMST-NrQobXduilWEqSw</td>\n",
       "      <td>Claire's Boutique</td>\n",
       "      <td>6020 E 82nd St, Ste 46</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>46250</td>\n",
       "      <td>39.908707</td>\n",
       "      <td>-86.065088</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsPriceRange2': '1', 'BusinessAccep...</td>\n",
       "      <td>Shopping, Jewelry, Piercing, Toy Stores, Beaut...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150344</th>\n",
       "      <td>mtGm22y5c2UHNXDFAjaPNw</td>\n",
       "      <td>Cyclery &amp; Fitness Center</td>\n",
       "      <td>2472 Troy Rd</td>\n",
       "      <td>Edwardsville</td>\n",
       "      <td>IL</td>\n",
       "      <td>62025</td>\n",
       "      <td>38.782351</td>\n",
       "      <td>-89.950558</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Fitness/Exercise Equipment, Eyewear &amp; Optician...</td>\n",
       "      <td>{'Monday': '9:0-20:0', 'Tuesday': '9:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150345</th>\n",
       "      <td>jV_XOycEzSlTx-65W906pg</td>\n",
       "      <td>Sic Ink</td>\n",
       "      <td>238 Apollo Beach Blvd</td>\n",
       "      <td>Apollo beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>33572</td>\n",
       "      <td>27.771002</td>\n",
       "      <td>-82.394910</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WheelchairAccessible': 'True', 'BusinessAcce...</td>\n",
       "      <td>Beauty &amp; Spas, Permanent Makeup, Piercing, Tattoo</td>\n",
       "      <td>{'Tuesday': '12:0-19:0', 'Wednesday': '12:0-19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150346 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id                      name   \n",
       "0       Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ  \\\n",
       "1       mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2       tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3       MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "4       mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
       "...                        ...                       ...   \n",
       "150341  IUQopTMmYQG-qRtBk-8QnA              Binh's Nails   \n",
       "150342  c8GjPIOTGVmIemT7j5_SyQ      Wild Birds Unlimited   \n",
       "150343  _QAMST-NrQobXduilWEqSw         Claire's Boutique   \n",
       "150344  mtGm22y5c2UHNXDFAjaPNw  Cyclery & Fitness Center   \n",
       "150345  jV_XOycEzSlTx-65W906pg                   Sic Ink   \n",
       "\n",
       "                                address           city state postal_code   \n",
       "0                1616 Chapala St, Ste 2  Santa Barbara    CA       93101  \\\n",
       "1       87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
       "2                  5255 E Broadway Blvd         Tucson    AZ       85711   \n",
       "3                           935 Race St   Philadelphia    PA       19107   \n",
       "4                         101 Walnut St     Green Lane    PA       18054   \n",
       "...                                 ...            ...   ...         ...   \n",
       "150341                3388 Gateway Blvd       Edmonton    AB     T6J 5H2   \n",
       "150342               2813 Bransford Ave      Nashville    TN       37204   \n",
       "150343           6020 E 82nd St, Ste 46   Indianapolis    IN       46250   \n",
       "150344                     2472 Troy Rd   Edwardsville    IL       62025   \n",
       "150345            238 Apollo Beach Blvd   Apollo beach    FL       33572   \n",
       "\n",
       "         latitude   longitude  stars  review_count  is_open   \n",
       "0       34.426679 -119.711197    5.0             7        0  \\\n",
       "1       38.551126  -90.335695    3.0            15        1   \n",
       "2       32.223236 -110.880452    3.5            22        0   \n",
       "3       39.955505  -75.155564    4.0            80        1   \n",
       "4       40.338183  -75.471659    4.5            13        1   \n",
       "...           ...         ...    ...           ...      ...   \n",
       "150341  53.468419 -113.492054    3.0            13        1   \n",
       "150342  36.115118  -86.766925    4.0             5        1   \n",
       "150343  39.908707  -86.065088    3.5             8        1   \n",
       "150344  38.782351  -89.950558    4.0            24        1   \n",
       "150345  27.771002  -82.394910    4.5             9        1   \n",
       "\n",
       "                                               attributes   \n",
       "0                           {'ByAppointmentOnly': 'True'}  \\\n",
       "1                  {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2       {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3       {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "4       {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
       "...                                                   ...   \n",
       "150341  {'ByAppointmentOnly': 'False', 'RestaurantsPri...   \n",
       "150342  {'BusinessAcceptsCreditCards': 'True', 'Restau...   \n",
       "150343  {'RestaurantsPriceRange2': '1', 'BusinessAccep...   \n",
       "150344  {'BusinessParking': '{'garage': False, 'street...   \n",
       "150345  {'WheelchairAccessible': 'True', 'BusinessAcce...   \n",
       "\n",
       "                                               categories   \n",
       "0       Doctors, Traditional Chinese Medicine, Naturop...  \\\n",
       "1       Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2       Department Stores, Shopping, Fashion, Home & G...   \n",
       "3       Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "4                               Brewpubs, Breweries, Food   \n",
       "...                                                   ...   \n",
       "150341                         Nail Salons, Beauty & Spas   \n",
       "150342  Pets, Nurseries & Gardening, Pet Stores, Hobby...   \n",
       "150343  Shopping, Jewelry, Piercing, Toy Stores, Beaut...   \n",
       "150344  Fitness/Exercise Equipment, Eyewear & Optician...   \n",
       "150345  Beauty & Spas, Permanent Makeup, Piercing, Tattoo   \n",
       "\n",
       "                                                    hours  \n",
       "0                                                    None  \n",
       "1       {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
       "2       {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
       "3       {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
       "4       {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n",
       "...                                                   ...  \n",
       "150341  {'Monday': '10:0-19:30', 'Tuesday': '10:0-19:3...  \n",
       "150342  {'Monday': '9:30-17:30', 'Tuesday': '9:30-17:3...  \n",
       "150343                                               None  \n",
       "150344  {'Monday': '9:0-20:0', 'Tuesday': '9:0-20:0', ...  \n",
       "150345  {'Tuesday': '12:0-19:0', 'Wednesday': '12:0-19...  \n",
       "\n",
       "[150346 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434c4cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31903"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "i = 0\n",
    "drop_index = []\n",
    "for index, row in df_b.iterrows():\n",
    "    if row[\"categories\"] is not None:\n",
    "        if (\"Restaurants\" in (row[\"categories\"]) or \"Food\" in (row[\"categories\"])) and row[\"is_open\"] == 1 and row[\"review_count\"] >= 15:\n",
    "            num+=1\n",
    "        else:\n",
    "            drop_index.append(index)\n",
    "    else:\n",
    "        drop_index.append(index)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e923b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3853096\n"
     ]
    }
   ],
   "source": [
    "df_b.drop(drop_index, axis=0, inplace=True)\n",
    "len(df_b)\n",
    "print(np.sum(list(df_b[\"review_count\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_lookup = {n: True for n in list(df_b[\"business_id\"])}\n",
    "business_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b082abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_file = open(\"D:/FlavorFriend/yelp_dataset/yelp_academic_dataset_review.json\", encoding='utf-8')\n",
    "cutoffs = []\n",
    "for i in range(int(7000000/100000)+1):\n",
    "    cutoffs.append(i*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(cutoffs)-1):\n",
    "    data = []\n",
    "    data_file = open(\"D:/FlavorFriend/yelp_dataset/yelp_academic_dataset_review.json\", encoding='utf-8')\n",
    "    for i, line in enumerate(data_file):\n",
    "        if i >= cutoffs[j] and i < cutoffs[j+1]:\n",
    "            data.append(json.loads(line))\n",
    "        if i > cutoffs[j+1]:\n",
    "            print(\"broken\")\n",
    "            break\n",
    "    df = pd.DataFrame(data)\n",
    "    data_file.close()\n",
    "    index_to_remove = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"business_id\"] not in business_lookup:\n",
    "            index_to_remove.append(index)\n",
    "    df.drop(index_to_remove, axis=0, inplace=True)\n",
    "    curr_df = pd.DataFrame(df)\n",
    "    curr_df.to_csv('D:/FlavorFriend/yelp_dataset/s/reviews_' + str(j) + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13654037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3990304,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "folder_path = 'D:/FlavorFriend/yelp_dataset/r'\n",
    "user_set = np.array([])\n",
    "review_counter = 0\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        review_counter += len(df)\n",
    "        user_list = np.array(df[\"user_id\"])\n",
    "        user_set = np.concatenate((user_set, user_list))\n",
    "\n",
    "print(user_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d993c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3990304"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_set = set(list(user_set)) #1309910\n",
    "print(len(user_set))\n",
    "review_counter #3990304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d52fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309910"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_lookup = {n: True for n in list(user_set)}\n",
    "len(user_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f41490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = []\n",
    "for i in range(int(2000000/100000)+1):\n",
    "    cutoffs.append(i*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_counter=0\n",
    "\n",
    "for j in range(len(cutoffs)-1):\n",
    "    data = []\n",
    "    data_file = open(\"D:/FlavorFriend/yelp_dataset/yelp_academic_dataset_user.json\", encoding='utf-8')\n",
    "    for i, line in enumerate(data_file):\n",
    "        if i >= cutoffs[j] and i < cutoffs[j+1]:\n",
    "            data.append(json.loads(line))\n",
    "        if i > cutoffs[j+1]:\n",
    "            print(\"broken\")\n",
    "            break\n",
    "    df = pd.DataFrame(data)\n",
    "    data_file.close()\n",
    "    index_to_remove = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"user_id\"] not in user_lookup:\n",
    "            r_counter +=1\n",
    "            index_to_remove.append(index)\n",
    "    df.drop(index_to_remove, axis=0, inplace=True)\n",
    "    curr_df = pd.DataFrame(df)\n",
    "    curr_df.to_csv('D:/FlavorFriend/yelp_dataset/u/users_' + str(j) + \".csv\", index=False)\n",
    "r_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53dde37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "\n",
    "sid_obj = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "184334b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.592, 'neu': 0.408, 'pos': 0.0, 'compound': -0.4404}\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994180202484131}]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "print(sentiment_dict)\n",
    "print(sentiment_analysis(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56608175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "k_array = []\n",
    "folder_path = 'D:/FlavorFriend/yelp_dataset/s/'\n",
    "user_set = np.array([])\n",
    "k = 0\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['score'] = df['text'].apply(lambda txt: sid.polarity_scores(txt))\n",
    "        df['negative'] = df['score'].apply(lambda txt: txt['neg'])\n",
    "        df['neutral'] = df['score'].apply(lambda txt: txt['neu'])\n",
    "        df['positive'] = df['score'].apply(lambda txt: txt['pos'])\n",
    "        df['compound'] = df['score'].apply(lambda txt: txt['compound'])\n",
    "        curr_df = pd.DataFrame(df)\n",
    "        k += 1\n",
    "        curr_df.to_csv('D:/FlavorFriend/yelp_dataset/vader/sentireviews_' + str(k) + \".csv\", index=False)\n",
    "        print(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "181e82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def truncate_text(text, max_words=250):\n",
    "    words = text.split(\" \")\n",
    "    if len(words) > max_words:\n",
    "        truncated_text = \" \".join(words[:max_words])\n",
    "        return truncated_text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2bdc68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_txt = None\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['text'] = df['text'].apply(truncate_text)\n",
    "        final_txt = df['text']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8e6f47e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(truncate_text)\n\u001b[1;32m---> 16\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m txt: sentiment_analysis(txt))\n\u001b[0;32m     17\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlabel_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m txt: txt[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mscore_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m txt: txt[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[75], line 16\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m     14\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(truncate_text)\n\u001b[1;32m---> 16\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m txt: sentiment_analysis(txt))\n\u001b[0;32m     17\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlabel_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m txt: txt[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mscore_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msent_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m txt: txt[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    122\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pipelines\\base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[0;32m   1102\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[0;32m   1103\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         )\n\u001b[0;32m   1107\u001b[0m     )\n\u001b[0;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pipelines\\base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1115\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1116\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1117\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1014\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1015\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1016\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1017\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1216\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[0;32m   1217\u001b[0m     input_ids,\n\u001b[0;32m   1218\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1219\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1220\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1221\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1222\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1223\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1224\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1225\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1228\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    843\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    845\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    846\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    847\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    851\u001b[0m )\n\u001b[1;32m--> 852\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    853\u001b[0m     embedding_output,\n\u001b[0;32m    854\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    855\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    856\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    857\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    858\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    859\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    860\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    861\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    862\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    863\u001b[0m )\n\u001b[0;32m    864\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    865\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    520\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    528\u001b[0m         hidden_states,\n\u001b[0;32m    529\u001b[0m         attention_mask,\n\u001b[0;32m    530\u001b[0m         layer_head_mask,\n\u001b[0;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    533\u001b[0m         past_key_value,\n\u001b[0;32m    534\u001b[0m         output_attentions,\n\u001b[0;32m    535\u001b[0m     )\n\u001b[0;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:453\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    450\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    451\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 453\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    455\u001b[0m )\n\u001b[0;32m    456\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    458\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:465\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m--> 465\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[0;32m    466\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:363\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 363\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    364\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Shaan\\miniconda3\\envs\\pytorc\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")\n",
    "k_array = []\n",
    "folder_path = 'D:/FlavorFriend/yelp_dataset/vader/'\n",
    "user_set = np.array([])\n",
    "k = 0\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['text'] = df['text'].apply(truncate_text)\n",
    "        df['sent_score'] = df['text'].apply(lambda txt: sentiment_analysis(txt))\n",
    "        df['label_'] = df['sent_score'].apply(lambda txt: txt['label'])\n",
    "        df['score_num'] = df['sent_score'].apply(lambda txt: txt['score'])\n",
    "        curr_df = pd.DataFrame(df)\n",
    "        k += 1\n",
    "        curr_df.to_csv('D:/FlavorFriend/yelp_dataset/vader_senti/sentireviews_' + str(k) + \".csv\", index=False)\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ac4699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1149974,\n",
       " 3: 1018160,\n",
       " 4: 910179,\n",
       " 5: 825054,\n",
       " 6: 756394,\n",
       " 7: 699122,\n",
       " 8: 650506,\n",
       " 9: 608795,\n",
       " 10: 572241,\n",
       " 11: 539264,\n",
       " 12: 510216,\n",
       " 13: 484022,\n",
       " 14: 460478,\n",
       " 15: 438825,\n",
       " 16: 418946,\n",
       " 17: 400865,\n",
       " 18: 384173,\n",
       " 19: 368935,\n",
       " 20: 354612,\n",
       " 21: 341579,\n",
       " 22: 329327,\n",
       " 23: 317859,\n",
       " 24: 307113}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vals = {}\n",
    "for i in range(len(k_array)):\n",
    "    k_vals[i+2] = k_array[i]\n",
    "k_vals\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
